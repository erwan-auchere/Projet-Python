{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['Indemne']==1,'grav']= 0\n",
    "df.loc[df['Blessé léger']==1,'grav']= 1\n",
    "df.loc[df['Blessé hospitalisé']==1,'grav']= 2\n",
    "df.loc[df['Tué']==1,'grav']= 3\n",
    "df['grav']=df['grav'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "g=['Indemne','Tué','Blessé hospitalisé','Blessé léger','grav']\n",
    "l=list(df.drop(columns=g).columns)\n",
    "X=df[l].values\n",
    "Y=df['grav'].values\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(X,Y,test_size=0.3,train_size=0.7)\n",
    "X_train=normalize(X_train)\n",
    "RandomForest=RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.35963225364685"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "RandomForest.fit(X_train,Y_train)\n",
    "end=time.time()\n",
    "t=end-start\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_hat=RandomForest.predict(normalize(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6552990292238821"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc1= accuracy_score(Y_test, Y_hat)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ceinture                        0.043464\n",
       "Casque                          0.029283\n",
       "VL seul                         0.022758\n",
       "Conducteur                      0.022123\n",
       "Avant gauche                    0.021187\n",
       "                                  ...   \n",
       "Obstacle : Véhicule sur rail    0.000000\n",
       "Vitesse limitée à nankm/h       0.000000\n",
       "Autre route                     0.000000\n",
       "Autre lieu                      0.000000\n",
       "110-114ans                      0.000000\n",
       "Length: 250, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(RandomForest.feature_importances_,index=l).sort_values(ascending=False)\n",
    "feature_imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après l'entretien avec le prof: \n",
    "- tester la corrélation des modalités de variables 'dummies' 2 à 2 et supprimer toutes celles dont la corr > valeur seuil (à fixer) lorsque ce sont 2 variables différents et rassembler en 1 modalité si c'est la même variable \n",
    "- reessayer le même randomforest() et regarder quelles variables sont sélectionnées (il faut choisir le nombre de variables à garder aussi)\n",
    "- serait ce utile de vérifier que long/lag sont pas utiles par ex en les ajoutant à randomforest et en ne les selectionnant pas? (peut être plus rigoureux qu'une corr)\n",
    "- implémenter la régression logistique après sélection \n",
    "- implémenter une méthode du gradient (voir sur data.gouv pour XGBOOST ou backward propag (celui ci est un RNN non?) ) \n",
    "- implémenter une autre méthode au choix (pourquoi pas KNN avec une métrique sur les discrets ou SVM) \n",
    "- --> pour l'implémentation, on préfèra une méthode de ML dite 'ordinale'\n",
    "- au choix (ou les deux) selon le temps disponible / difficulté : webscrapper une nouvelle variable (température/ humidité ?), ajouter une carte avec rond : taille du rond= nb d'accident, couleur du rond= moyenne de la gravité sur ce nb d'accidents ... possibilité de zoomer/ dézoomer (genre avoir une couleur orange sur l'échelle d'un département mais rouge lorqu'on zoom sur une commune x du département et vert sur une autre commune y)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
